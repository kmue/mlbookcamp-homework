{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bba4134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split # for train test split\n",
    "from sklearn.feature_extraction import DictVectorizer # for one-hot encoding\n",
    "from sklearn.tree import DecisionTreeRegressor # decision tree regressor (for q1)\n",
    "from sklearn.tree import export_text\n",
    "#import matplotlib as mpl\n",
    "#import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "348ada9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c9e16c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a0685fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 Preliminary tasks\n",
    "# 0.1 Use only the following columns:\n",
    "#     'latitude', 'longitude', 'housing_median_age', 'total_rooms',\n",
    "#     'total_bedrooms', 'population', 'households', 'median_income',\n",
    "#     'median_house_value', 'ocean_proximity'\n",
    "df = df[['latitude', 'longitude', 'housing_median_age', 'total_rooms',\n",
    "         'total_bedrooms', 'population', 'households', 'median_income',\n",
    "         'median_house_value','ocean_proximity']].copy()\n",
    "# 0.2 Fill NAs with 0.\n",
    "# df.isna().sum()[df.isna().sum()>0] # --> 207 NAs in column 'total_bedrooms'\n",
    "df['total_bedrooms'] = df['total_bedrooms'].fillna(0, inplace=False)\n",
    "\n",
    "# 0.3 Apply the log tranform to median_house_value.\n",
    "df['log_median_house_value'] = np.log1p(df['median_house_value'])\n",
    "\n",
    "# 0.4 Do train/validation/test split with 60%/20%/20% distribution.\n",
    "#     Use the train_test_split function and set the random_state parameter to 1.\n",
    "X_train_valid, X_test, y_train_valid, y_test = train_test_split(\n",
    "    df.drop(['median_house_value', 'log_median_house_value'], axis = 1),\n",
    "    df[['log_median_house_value']],\n",
    "    train_size = 0.8,\n",
    "    test_size = 0.2,\n",
    "    random_state = 1)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_valid,\n",
    "    y_train_valid,\n",
    "    train_size = 0.75,\n",
    "    test_size = 0.25,\n",
    "    random_state = 1)\n",
    "\n",
    "# extract column names to use as labels later\n",
    "X_names = X_train.columns.values.tolist()\n",
    "\n",
    "# 0.5 Use DictVectorizer to turn the dataframe into matrices.\n",
    "# train_dict = X_train.to_dict(orient='records')\n",
    "# dv_train = DictVectorizer(sparse=False)\n",
    "# dv_train.fit(train_dict)\n",
    "# X_train = dv.transform(train_dict)\n",
    "\n",
    "# valid_dict = X_valid.to_dict(orient='records')\n",
    "# dv_valid = DictVectorizer(sparse=False)\n",
    "# dv_valid.fit(valid_dict)\n",
    "# X_valid = dv.transform(valid_dict)\n",
    "\n",
    "# test_dict = X_test.to_dict(orient='records')\n",
    "# dv_test = DictVectorizer(sparse=False)\n",
    "# dv_test.fit(test_dict)\n",
    "# X_test = dv.transform(test_dict)\n",
    "\n",
    "# TO DO\n",
    "# concatenate X_train, X_valid, X_test\n",
    "# run DictVectorizer over everything to catch all possible category values\n",
    "# disassemble resulting array into X_train, X_valid, X_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b4d0e543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['households' 'housing_median_age' 'latitude' 'longitude' 'median_income'\n",
      " 'ocean_proximity=<1H OCEAN' 'ocean_proximity=INLAND'\n",
      " 'ocean_proximity=ISLAND' 'ocean_proximity=NEAR BAY'\n",
      " 'ocean_proximity=NEAR OCEAN' 'population' 'total_bedrooms' 'total_rooms'] \n",
      " ['households' 'housing_median_age' 'latitude' 'longitude' 'median_income'\n",
      " 'ocean_proximity=<1H OCEAN' 'ocean_proximity=INLAND'\n",
      " 'ocean_proximity=ISLAND' 'ocean_proximity=NEAR BAY'\n",
      " 'ocean_proximity=NEAR OCEAN' 'population' 'total_bedrooms' 'total_rooms'] \n",
      " ['households' 'housing_median_age' 'latitude' 'longitude' 'median_income'\n",
      " 'ocean_proximity=<1H OCEAN' 'ocean_proximity=INLAND'\n",
      " 'ocean_proximity=NEAR BAY' 'ocean_proximity=NEAR OCEAN' 'population'\n",
      " 'total_bedrooms' 'total_rooms']\n",
      "(12384, 12) (4128, 12) (4128, 12)\n"
     ]
    }
   ],
   "source": [
    "print(dv_train.get_feature_names_out(), \"\\n\",\n",
    "      dv_valid.get_feature_names_out(), \"\\n\", \n",
    "      dv_test.get_feature_names_out())\n",
    "print(X_train.shape, X_valid.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "282ea7e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feature_names must contain 12 elements, got 13",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [99]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m regressor\u001b[38;5;241m.\u001b[39mfit(X_train, \n\u001b[1;32m      7\u001b[0m               y_train)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Which feature is used for splitting the data?\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#print(export_text(regressor))\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mexport_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregressor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdv_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/tree/_export.py:999\u001b[0m, in \u001b[0;36mexport_text\u001b[0;34m(decision_tree, feature_names, max_depth, spacing, decimals, show_weights)\u001b[0m\n\u001b[1;32m    996\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_depth bust be >= 0, given \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m max_depth)\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(feature_names) \u001b[38;5;241m!=\u001b[39m tree_\u001b[38;5;241m.\u001b[39mn_features:\n\u001b[0;32m--> 999\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_names must contain \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m elements, got \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;241m%\u001b[39m (tree_\u001b[38;5;241m.\u001b[39mn_features, \u001b[38;5;28mlen\u001b[39m(feature_names))\n\u001b[1;32m   1002\u001b[0m     )\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spacing \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1005\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspacing must be > 0, given \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m spacing)\n",
      "\u001b[0;31mValueError\u001b[0m: feature_names must contain 12 elements, got 13"
     ]
    }
   ],
   "source": [
    "# Question 1\n",
    "\n",
    "# Let's train a decision tree regressor to predict the median_house_value variable.\n",
    "regressor = DecisionTreeRegressor(max_depth = 1)\n",
    "# Train a model with max_depth=1.\n",
    "regressor.fit(X_train, \n",
    "              y_train)\n",
    "\n",
    "# Which feature is used for splitting the data?\n",
    "#print(export_text(regressor))\n",
    "export_text(regressor, feature_names=dv_train.get_feature_names_out())\n",
    "#print(\"X_train feature at index position 6 is \\n\", dv_train.get_feature_names_out()[6])\n",
    "# dv_train.get_feature_names_out()\n",
    "\n",
    "# ocean_proximity=INLAND\n",
    "# total_rooms\n",
    "# latitude\n",
    "# population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "96e95983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['households', 'housing_median_age', 'latitude', 'longitude',\n",
       "       'median_income', 'ocean_proximity=<1H OCEAN',\n",
       "       'ocean_proximity=INLAND', 'ocean_proximity=ISLAND',\n",
       "       'ocean_proximity=NEAR BAY', 'ocean_proximity=NEAR OCEAN',\n",
       "       'population', 'total_bedrooms', 'total_rooms'], dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv_train.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fb96ef54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., ..., 0., 1., 1.])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b830c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2\n",
    "\n",
    "# Train a random forest model with these parameters:\n",
    "\n",
    "# n_estimators=10\n",
    "# random_state=1\n",
    "# n_jobs=-1 (optional - to make training faster)\n",
    "# What's the RMSE of this model on validation?\n",
    "\n",
    "# 0.05\n",
    "# 0.25\n",
    "# 0.55\n",
    "# 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ddf933a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3\n",
    "\n",
    "# Now let's experiment with the n_estimators parameter\n",
    "\n",
    "# Try different values of this parameter from 10 to 200 with step 10.\n",
    "# Set random_state to 1.\n",
    "# Evaluate the model on the validation dataset.\n",
    "# After which value of n_estimators does RMSE stop improving?\n",
    "\n",
    "# 10\n",
    "# 55\n",
    "# 75\n",
    "# 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e7bcc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4\n",
    "\n",
    "# Let's select the best max_depth:\n",
    "\n",
    "# Try different values of max_depth: [10, 15, 20, 25]\n",
    "# For each of these values, try different values of n_estimators from 10 till 200 (with step 10)\n",
    "# Fix the random seed: random_state=1\n",
    "# What's the best max_depth:\n",
    "\n",
    "# 10\n",
    "# 15\n",
    "# 20\n",
    "# 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f40bf2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5\n",
    "\n",
    "# We can extract feature importance information from tree-based models.\n",
    "\n",
    "# At each step of the decision tree learning algorith, it finds the best split. When doint it, we can calculate \"gain\" - the reduction in impurity before and after the split. This gain is quite useful in understanding what are the imporatant features for tree-based models.\n",
    "\n",
    "# In Scikit-Learn, tree-based models contain this information in the feature_importances_ field.\n",
    "\n",
    "# For this homework question, we'll find the most important feature:\n",
    "\n",
    "# Train the model with these parametes:\n",
    "# n_estimators=10,\n",
    "# max_depth=20,\n",
    "# random_state=1,\n",
    "# n_jobs=-1 (optional)\n",
    "# Get the feature importance information from this model\n",
    "# What's the most important feature?\n",
    "\n",
    "# total_rooms\n",
    "# median_income\n",
    "# total_bedrooms\n",
    "# longitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc963ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 6\n",
    "\n",
    "# Now let's train an XGBoost model! For this question, we'll tune the eta parameter:\n",
    "\n",
    "# Install XGBoost\n",
    "# Create DMatrix for train and validation\n",
    "# Create a watchlist\n",
    "# Train a model with these parameters for 100 rounds:\n",
    "# xgb_params = {\n",
    "#     'eta': 0.3, \n",
    "#     'max_depth': 6,\n",
    "#     'min_child_weight': 1,\n",
    "#     \n",
    "#     'objective': 'reg:squarederror',\n",
    "#     'nthread': 8,\n",
    "#     \n",
    "#     'seed': 1,\n",
    "#     'verbosity': 1,\n",
    "# }\n",
    "# Now change eta first to 0.1 and then to 0.01\n",
    "\n",
    "# Which eta leads to the best RMSE score on the validation dataset?\n",
    "\n",
    "# 0.3\n",
    "# 0.1\n",
    "# Both gives same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f398410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5971d90e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
